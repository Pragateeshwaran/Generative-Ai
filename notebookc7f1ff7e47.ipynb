{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T11:38:27.173484Z",
     "iopub.status.busy": "2025-04-07T11:38:27.173130Z",
     "iopub.status.idle": "2025-04-07T11:38:36.225894Z",
     "shell.execute_reply": "2025-04-07T11:38:36.225174Z",
     "shell.execute_reply.started": "2025-04-07T11:38:27.173459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install -U transformers \n",
    "# %pip install -U datasets \n",
    "# %pip install -U accelerate \n",
    "# %pip install -U peft \n",
    "# %pip install -U trl \n",
    "# %pip install -U bitsandbytes \n",
    "# %pip install -U wandb\n",
    "    \n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, SFTConfig # Removed setup_chat_format as SFTTrainer handles it\n",
    "\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T11:38:36.227842Z",
     "iopub.status.busy": "2025-04-07T11:38:36.227123Z",
     "iopub.status.idle": "2025-04-07T11:38:49.864773Z",
     "shell.execute_reply": "2025-04-07T11:38:49.864132Z",
     "shell.execute_reply.started": "2025-04-07T11:38:36.227807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnamasivaayaml\u001b[0m (\u001b[33mmepco-iot-7thsem\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250407_113843-xx5ygyvw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL/runs/xx5ygyvw?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5' target=\"_blank\">eternal-salad-22</a></strong> to <a href='https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5' target=\"_blank\">https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL/runs/xx5ygyvw?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5' target=\"_blank\">https://wandb.ai/mepco-iot-7thsem/Fine-tune%20Llama%203.1%208B%20on%20Text-to-SQL/runs/xx5ygyvw?apiKey=78cbc459d46c8fbdf7d2f669a09f835112ce4ec5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Login ---\n",
    "hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n",
    "login(token = hf_token)\n",
    "\n",
    "wb_token = user_secrets.get_secret(\"WANDB_TOKEN\")\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.1 8B on Text-to-SQL',\n",
    "    job_type=\"training\",\n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T11:38:49.866782Z",
     "iopub.status.busy": "2025-04-07T11:38:49.866479Z",
     "iopub.status.idle": "2025-04-07T11:38:49.925829Z",
     "shell.execute_reply": "2025-04-07T11:38:49.924976Z",
     "shell.execute_reply.started": "2025-04-07T11:38:49.866746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Eager Attention & FP16\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "base_model = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
    "new_model = \"llama-3.1-8b-it-v2-fine-tuned-combined-complex-queries\"\n",
    "# Using a placeholder instruction - REPLACE with your actual instruction if it's static\n",
    "# If it varies per example, you need a different formatting approach.\n",
    "instruction = \"Given the database schema and a question, generate the SQL query that answers the question.\"\n",
    "dataset_name = \"/kaggle/input/union-queries-v4-free-lance/training_data_v4.json\"\n",
    "MAX_SEQ_LENGTH = 2048 # IMPORTANT: Choose a reasonable max length\n",
    "\n",
    "# --- Set torch dtype and attention implementation ---\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn # Already run in setup? Ensure it's installed\n",
    "    print(\"Using Flash Attention 2 & BF16\")\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    # Set TrainingArguments precision accordingly\n",
    "    use_bf16 = True\n",
    "    use_fp16 = False\n",
    "else:\n",
    "    print(\"Using Eager Attention & FP16\")\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n",
    "    # Set TrainingArguments precision accordingly\n",
    "    use_bf16 = False\n",
    "    use_fp16 = True\n",
    "\n",
    "# --- QLoRA config ---\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T11:38:49.927266Z",
     "iopub.status.busy": "2025-04-07T11:38:49.927002Z",
     "iopub.status.idle": "2025-04-07T11:39:13.309107Z",
     "shell.execute_reply": "2025-04-07T11:39:13.308162Z",
     "shell.execute_reply.started": "2025-04-07T11:38:49.927244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0733459c827a4da383fc1b04d3f843a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Setting pad_token to eos_token\n"
     ]
    }
   ],
   "source": [
    "# --- Load model ---\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", # Let HF handle device placement\n",
    "    attn_implementation=attn_implementation,\n",
    "    torch_dtype=torch_dtype, # Set dtype during loading as well\n",
    ")\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# --- Load tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "# Set pad token if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"Setting pad_token to eos_token\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id # Ensure model config matches\n",
    "\n",
    "# It's often better to prepare the model *before* adding LoRA adapters if using gradient checkpointing\n",
    "model.gradient_checkpointing_enable() # Enable gradient checkpointing\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T11:39:13.310412Z",
     "iopub.status.busy": "2025-04-07T11:39:13.310080Z",
     "iopub.status.idle": "2025-04-07T11:39:13.315920Z",
     "shell.execute_reply": "2025-04-07T11:39:13.315151Z",
     "shell.execute_reply.started": "2025-04-07T11:39:13.310378Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "You are an expert Text-to-SQL converter specifically trained for the SALESIT database environment, likely using a Snowflake or PostgreSQL-like SQL dialect (supporting `||` concatenation and `lower()`). Your task is to translate the user's natural language question into a syntactically correct and executable SQL query based *only* on the provided database schema and adhering to specific standard structures and filtering logic.\n",
    "\n",
    "**Core Task:** Generate a single, valid SQL query reflecting the user's request.\n",
    "\n",
    "**Key Instructions & Standard Patterns:**\n",
    "\n",
    "1.  **Schema Analysis:** Carefully examine the provided `CREATE TABLE` statements (or schema description) for table names (e.g., `ALL_OPPORTUNITY_VW`, `sfdc_rnwl_oppty_share_sales_level_vw`, `sfdc_rnwl_oppty_team_vw`), columns, types, and keys. Use exact, fully qualified names (e.g., `SALESIT_DB.SALESIT_SFDCANA_STG.ALL_OPPORTUNITY_VW`) and appropriate aliases (e.g., `opty`, `ssl`, `login_usr`, `otv`).\n",
    "2.  **Standard Joins for Opportunities:** Queries involving \"renewal opportunities\" typically require joining `ALL_OPPORTUNITY_VW` (aliased as `opty`) with `sfdc_rnwl_oppty_share_sales_level_vw` (aliased as `ssl` for territory checks) and again with `sfdc_rnwl_oppty_share_sales_level_vw` (aliased as `login_usr` for user territory mapping). Often, a join to `sfdc_rnwl_oppty_team_vw` (aliased as `otv`) is also needed for comprehensive access checks.\n",
    "    *   Territory Join: `opty.TERRITORY_ID = ssl.TERRITORYID`\n",
    "    *   User Territory Join: `ssl.parent_territories LIKE '%' || login_usr.territory_name || '%'`\n",
    "    *   Opportunity Team Join: `opty.opportunity_id = otv.opportunity_id`\n",
    "3.  **Mandatory Filters:** Unless the user explicitly asks otherwise, *always* include these standard filters for opportunity queries:\n",
    "    *   `opty.IS_CLOSED = FALSE`\n",
    "    *   `opty.RECORD_TYPE_ID = '01234000000Boc4AAC'` (Renewal Opportunity Record Type)\n",
    "    *   `WHERE 1 = 1` (Maintain this pattern if present in examples)\n",
    "4.  **User Context Placeholders:**\n",
    "    *   Recognize when the user's question implies context about the *requesting user* (e.g., \"my opportunities\", filtering implicit to the user).\n",
    "    *   Use the placeholders `{{logged_user}}` (representing the logged-in user's alias/ID) and `{{req_user}}` (representing the user making the request, potentially for wider access checks) in the `WHERE` clauses to filter data based on user permissions, ownership, territory, and opportunity team access.\n",
    "    *   Apply standard user filtering logic, often involving `lower()` for case-insensitive matching against fields like `OPPORTUNITY_OWNER_FULLNAME`, `opportunity_owner_userid`, `opty_access_users_list`, `ssl.alias`, `ssl.user_full_name`. Examples:\n",
    "        *   `login_usr.alias = '{{logged_user}}'`\n",
    "        *   Complex `OR` conditions checking ownership/access lists against `{{req_user}}` (e.g., `(lower(OPPORTUNITY_OWNER_FULLNAME) LIKE lower('%{{req_user}}%') OR opportunity_owner_userid = '{{req_user}}' OR lower(opty_access_users_list) LIKE lower('%{{req_user}}%'))` )\n",
    "5.  **Standard UNION Structure:** Many queries require a `UNION` of two similar `SELECT DISTINCT` statements. This often accounts for different permission paths (e.g., direct access/team membership vs. territory hierarchy). The second part of the `UNION` might have slightly simpler permission checks (e.g., omitting the `otv` join and related checks). Apply this `UNION` structure consistently for standard opportunity requests.\n",
    "6.  **Standard Output Columns:** For opportunity queries, typically select the following columns unless specified otherwise: `opty.opportunity_id`, `OPPORTUNITY_OWNER_FULLNAME`, `opportunity_name`, `deal_id`, `stage_name`, `close_date`, `prior_contract_expiration_date`, `account_name`, `prior_contract_notes`, `prior_sales_order_number_s`, `expected_product_amt`, `expected_service_amt`, `expected_total_atr_000s`. Use `DISTINCT`.\n",
    "7.  **Standard Ordering & Limit:** Unless the user specifies otherwise, end the query with `ORDER BY EXPECTED_TOTAL_ATR_000S desc LIMIT 1000`.\n",
    "8.  **Interpret User Criteria:** Map the specific criteria from the user's question (e.g., `stage_name = '3 - Proposal'`, `TOTAL_PRIOR_ATR_000S > 25.0`, `ACCOUNT_COUNTRY = UPPER('PANAMA')`) into the appropriate `WHERE` clause conditions within *both* parts of the `UNION` structure. Handle case sensitivity appropriately (e.g., using `lower()` or `UPPER()`).\n",
    "9.  **Schema Adherence:** Only use tables and columns explicitly mentioned in the provided schema. Do not invent tables, columns, or relationships.\n",
    "10. **Output Format:** Respond *only* with the generated SQL query. Do not include any explanations, comments, markdown formatting (like ```sql ... ```), or introductory text.\n",
    "\n",
    "**Example Interaction Flow:**\n",
    "\n",
    "1.  System receives Schema + User Question + User Context (`logged_user`, `req_user`).\n",
    "2.  System applies instructions above, constructing the complex SQL with standard joins, filters, UNION, user context placeholders, specific user criteria, ordering, and limit.\n",
    "3.  System outputs *only* the final SQL query.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-07T11:39:13.317157Z",
     "iopub.status.busy": "2025-04-07T11:39:13.316834Z",
     "iopub.status.idle": "2025-04-07T11:39:13.983889Z",
     "shell.execute_reply": "2025-04-07T11:39:13.983104Z",
     "shell.execute_reply.started": "2025-04-07T11:39:13.317124Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded and split.\n",
      "Mapping formatting function...\n",
      "Dataset formatting complete.\n",
      "Sample formatted text: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are an expert Text-to-SQL converter specifically trained for the SALESIT database environment, likely using a Snowflake or PostgreSQL-like SQL dialect (supporting `||` concatenation and `lower()`). Your task is to translate the user's natural language question into a syntactically correct and executable SQL query based *only* on the provided database schema and adhering to specific standard structures and filtering logic.\n",
      "\n",
      "**Core Task:** Generate a single, valid SQL query reflecting the user's request.\n",
      "\n",
      "**Key Instructions & Standard Patterns:**\n",
      "\n",
      "1.  **Schema Analysis:** Carefully examine the provided `CREATE TABLE` statements (or schema description) for table names (e.g., `ALL_OPPORTUNITY_VW`, `sfdc_rnwl_oppty_share_sales_level_vw`, `sfdc_rnwl_oppty_team_vw`), columns, types, and keys. Use exact, fully qualified names (e.g., `SALESIT_DB.SALESIT_SFDCANA_STG.ALL_OPPORTUNITY_VW`) and appropriate aliases (e.g., `opty`, `ssl`, `login_usr`, `otv`).\n",
      "2.  **Standard Joins for Opportunities:** Queries involving \"renewal opportunities\" typically require joining `ALL_OPPORTUNITY_VW` (aliased as `opty`) with `sfdc_rnwl_oppty_share_sales_level_vw` (aliased as `ssl` for territory checks) and again with `sfdc_rnwl_oppty_share_sales_level_vw` (aliased as `login_usr` for user territory mapping). Often, a join to `sfdc_rnwl_oppty_team_vw` (aliased as `otv`) is also needed for comprehensive access checks.\n",
      "    *   Territory Join: `opty.TERRITORY_ID = ssl.TERRITORYID`\n",
      "    *   User Territory Join: `ssl.parent_territories LIKE '%' || login_usr.territory_name || '%'`\n",
      "    *   Opportunity Team Join: `opty.opportunity_id = otv.opportunity_id`\n",
      "3.  **Mandatory Filters:** Unless the user explicitly asks otherwise, *always* include these standard filters for opportunity queries:\n",
      "    *   `opty.IS_CLOSED = FALSE`\n",
      "    *   `opty.RECORD_TYPE_ID = '01234000000Boc4AAC'` (Renewal Opportunity Record Type)\n",
      "    *   `WHERE 1 = 1` (Maintain this pattern if present in examples)\n",
      "4.  **User Context Placeholders:**\n",
      "    *   Recognize when the user's question implies context about the *requesting user* (e.g., \"my opportunities\", filtering implicit to the user).\n",
      "    *   Use the placeholders `{{logged_user}}` (representing the logged-in user's alias/ID) and `{{req_user}}` (representing the user making the request, potentially for wider access checks) in the `WHERE` clauses to filter data based on user permissions, ownership, territory, and opportunity team access.\n",
      "    *   Apply standard user filtering logic, often involving `lower()` for case-insensitive matching against fields like `OPPORTUNITY_OWNER_FULLNAME`, `opportunity_owner_userid`, `opty_access_users_list`, `ssl.alias`, `ssl.user_full_name`. Examples:\n",
      "        *   `login_usr.alias = '{{logged_user}}'`\n",
      "        *   Complex `OR` conditions checking ownership/access lists against `{{req_user}}` (e.g., `(lower(OPPORTUNITY_OWNER_FULLNAME) LIKE lower('%{{req_user}}%') OR opportunity_owner_userid = '{{req_user}}' OR lower(opty_access_users_list) LIKE lower('%{{req_user}}%'))` )\n",
      "5.  **Standard UNION Structure:** Many queries require a `UNION` of two similar `SELECT DISTINCT` statements. This often accounts for different permission paths (e.g., direct access/team membership vs. territory hierarchy). The second part of the `UNION` might have slightly simpler permission checks (e.g., omitting the `otv` join and related checks). Apply this `UNION` structure consistently for standard opportunity requests.\n",
      "6.  **Standard Output Columns:** For opportunity queries, typically select the following columns unless specified otherwise: `opty.opportunity_id`, `OPPORTUNITY_OWNER_FULLNAME`, `opportunity_name`, `deal_id`, `stage_name`, `close_date`, `prior_contract_expiration_date`, `account_name`, `prior_contract_notes`, `prior_sales_order_number_s`, `expected_product_amt`, `expected_service_amt`, `expected_total_atr_000s`. Use `DISTINCT`.\n",
      "7.  **Standard Ordering & Limit:** Unless the user specifies otherwise, end the query with `ORDER BY EXPECTED_TOTAL_ATR_000S desc LIMIT 1000`.\n",
      "8.  **Interpret User Criteria:** Map the specific criteria from the user's question (e.g., `stage_name = '3 - Proposal'`, `TOTAL_PRIOR_ATR_000S > 25.0`, `ACCOUNT_COUNTRY = UPPER('PANAMA')`) into the appropriate `WHERE` clause conditions within *both* parts of the `UNION` structure. Handle case sensitivity appropriately (e.g., using `lower()` or `UPPER()`).\n",
      "9.  **Schema Adherence:** Only use tables and columns explicitly mentioned in the provided schema. Do not invent tables, columns, or relationships.\n",
      "10. **Output Format:** Respond *only* with the generated SQL query. Do not include any explanations, comments, markdown formatting (like ```sql ... ```), or introductory text.\n",
      "\n",
      "**Example Interaction Flow:**\n",
      "\n",
      "1.  System receives Schema + User Question + User Context (`logged_user`, `req_user`).\n",
      "2.  System applies instructions above, constructing the complex SQL with standard joins, filters, UNION, user context placeholders, specific user criteria, ordering, and limit.\n",
      "3.  System outputs *only* the final SQL query.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Pull all renewal opportunities that are linked to the partner information of MDS for Computer Systems.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "SELECT DISTINCT opty.opportunity_id, OPPORTUNITY_OWNER_FULLNAME, opportunity_name, deal_id, stage_name, close_date, prior_contract_expiration_date, account_name, prior_contract_notes, prior_sales_order_number_s, expected_product_amt, expected_service_amt, expected_total_atr_000s FROM SALESIT_DB.SALESIT_SFDCANA_STG.ALL_OPPORTUNITY_VW opty JOIN salesit_db.salesit_sfdcana_stg.sfdc_rnwl_oppty_share_sales_level_vw ssl ON opty.TERRITORY_ID = ssl.TERRITORYID JOIN salesit_db.salesit_sfdcana_stg.sfdc_rnwl_oppty_share_sales_level_vw login_usr ON ssl.parent_territories LIKE '%' || login_usr.territory_name || '%' JOIN salesit_db.salesit_sfdcana_stg.sfdc_rnwl_oppty_team_vw otv ON opty.opportunity_id = otv.opportunity_id WHERE 1 = 1 AND opty.IS_CLOSED = FALSE AND RECORD_TYPE_ID = '01234000000Boc4AAC' AND login_usr.alias = '{{logged_user}}' AND opty_access_users_list LIKE '%{{req_user}}%' AND (lower(OPPORTUNITY_OWNER_FULLNAME) LIKE lower('%{{req_user}}%') OR opportunity_owner_userid = '{{req_user}}' OR lower(opty_access_users_list) LIKE lower('%{{req_user}}%')) AND (lower(ssl.alias) LIKE lower('%{{req_user}}%') OR lower(ssl.user_full_name) LIKE lower('%{{req_user}}%') OR lower(opty_access_users_list) LIKE lower('%{{req_user}}%')) AND CONTAINS(LOWER(RENEWAL_PARTNER_INFO), LOWER('MDS FOR COMPUTER SYSTEMS')) UNION SELECT DISTINCT opportunity_id, OPPORTUNITY_OWNER_FULLNAME, opportunity_name, deal_id, stage_name, close_date, prior_contract_expiration_date, account_name, prior_contract_notes, prior_sales_order_number_s, expected_product_amt, expected_service_amt, expected_total_atr_000s FROM SALESIT_DB.SALESIT_SFDCANA_STG.ALL_OPPORTUNITY_VW opty JOIN salesit_db.salesit_sfdcana_stg.sfdc_rnwl_oppty_share_sales_level_vw ssl ON opty.TERRITORY_ID = ssl.TERRITORYID JOIN salesit_db.salesit_sfdcana_stg.sfdc_rnwl_oppty_share_sales_level_vw login_usr ON ssl.parent_territories LIKE '%' || login_usr.territory_name || '%' WHERE 1 = 1 AND opty.IS_CLOSED = FALSE AND RECORD_TYPE_ID = '01234000000Boc4AAC' AND login_usr.alias = '{{logged_user}}' AND (lower(OPPORTUNITY_OWNER_FULLNAME) LIKE lower('%{{req_user}}%') OR opportunity_owner_userid = '{{req_user}}') AND (lower(ssl.alias) LIKE lower('%{{req_user}}%') OR lower(ssl.user_full_name) LIKE lower('%{{req_user}}%')) AND CONTAINS(LOWER(RENEWAL_PARTNER_INFO), LOWER('MDS FOR COMPUTER SYSTEMS')) ORDER BY EXPECTED_TOTAL_ATR_000S desc LIMIT 1000<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# --- Load and prepare dataset ---\n",
    "print(\"Loading dataset...\")\n",
    "data_files = {\"train\": dataset_name}\n",
    "dataset = load_dataset(\"json\", data_files=data_files)[\"train\"]\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "print(\"Dataset loaded and split.\")\n",
    "\n",
    "# --- Formatting function ---\n",
    "# Ensure you have the 'instruction' defined globally or passed correctly\n",
    "def formatting_prompts_func(examples):\n",
    "    output_texts = []\n",
    "    for i in range(len(examples[\"question\"])):\n",
    "        # Assumes a fixed 'instruction' defined globally\n",
    "        # If instruction is part of your JSON per row, use examples[\"instruction\"][i]\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": examples[\"question\"][i]},\n",
    "            {\"role\": \"assistant\", \"content\": examples[\"query\"][i]}\n",
    "        ]\n",
    "        # Apply template, DON'T tokenize here, SFTTrainer handles it\n",
    "        chat_string = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        output_texts.append(chat_string)\n",
    "        \n",
    "    return {\"text\": output_texts } # Create the 'text' column SFTTrainer expects by default\n",
    "\n",
    "print(\"Mapping formatting function...\")\n",
    "# Important: Use remove_columns to avoid carrying unused data into the trainer\n",
    "columns_to_remove = list(dataset['train'].features)\n",
    "if \"text\" in columns_to_remove: # Don't remove the column we just created\n",
    "     columns_to_remove.remove(\"text\")\n",
    "     \n",
    "train_dataset = dataset['train'].map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    "    remove_columns=columns_to_remove # Remove original columns\n",
    ")\n",
    "eval_dataset = dataset['test'].map(\n",
    "    formatting_prompts_func,\n",
    "    batched=True,\n",
    "    remove_columns=columns_to_remove # Remove original columns\n",
    ")\n",
    "print(\"Dataset formatting complete.\")\n",
    "print(\"Sample formatted text:\", train_dataset[1]['text']) # Verify format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-07T11:39:13.985322Z",
     "iopub.status.busy": "2025-04-07T11:39:13.984855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-051738391546>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Optional: Clear cache just before training (might help slightly with fragmentation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2563\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2565\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m                     ):\n\u001b[1;32m   2567\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- LoRA Config ---\n",
    "# Define the target modules for Llama 3 (check model card or experiment)\n",
    "# Common targets for Llama-like models:\n",
    "target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16, # You can try reducing this to 8 if memory is still tight\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=target_modules # Use the defined list\n",
    ")\n",
    "\n",
    "# Apply PEFT model AFTER preparing for kbit training\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters() # Good practice to check\n",
    "\n",
    "# --- Training Arguments ---\n",
    "training_arguments = SFTConfig(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,  # REDUCED batch size\n",
    "    per_device_eval_batch_size=1,   # Keep eval batch size low\n",
    "    gradient_accumulation_steps=8, # INCREASED accumulation to compensate (effective batch size 1*8=8)\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",    # Changed from 'eval_strategy'\n",
    "    eval_steps=0.2,                 # Evaluate every 20% of steps\n",
    "    logging_steps=10,               # Log less frequently to reduce noise\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=use_fp16,                  # ENABLED mixed precision\n",
    "    bf16=use_bf16,                  # ENABLED mixed precision\n",
    "    # gradient_checkpointing=True,  # MOVED enabling this earlier for kbit compatibility\n",
    "    group_by_length=True,           # Helps pack batches efficiently\n",
    "    lr_scheduler_type=\"cosine\",     # A common scheduler\n",
    "    report_to=\"wandb\",\n",
    "    \n",
    "    # Important for gradient checkpointing compatibility\n",
    "    # ddp_find_unused_parameters=False, # Only needed for DDP, not single GPU\n",
    "    \n",
    "    # tokenizer=tokenizer,            # PASS the tokenizer\n",
    "    dataset_text_field=\"text\",      # EXPLICITLY specify the text field\n",
    "    max_seq_length=MAX_SEQ_LENGTH,  # EXPLICITLY set max sequence length\n",
    "    packing=False,                  # Set packing to False, as we pre-formatted\n",
    ")\n",
    "\n",
    "# --- SFT Trainer ---\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "print(\"Starting training...\")\n",
    "# Optional: Clear cache just before training (might help slightly with fragmentation)\n",
    "# torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# --- Finish W&B Run ---\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Inference Example ---\n",
    "print(\"\\n--- Running Inference Example ---\")\n",
    "# Ensure model is on GPU for inference if device_map put parts elsewhere\n",
    "# model.to(\"cuda\") # Usually device_map='auto' handles this, but double-check if needed\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": \"Can you provide me with renewal opportunities where the stage is '3 - Proposal'?\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=False, truncation=True).to(model.device) # Use model.device\n",
    "\n",
    "# Generate text\n",
    "# Use torch.no_grad() for inference to save memory\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=512, num_return_sequences=1, # Reduced max_new_tokens a bit\n",
    "                             do_sample=True, # Add sampling for potentially better results\n",
    "                             temperature=0.6,\n",
    "                             top_p=0.9,\n",
    "                             pad_token_id=tokenizer.eos_token_id) # Ensure pad token is EOS\n",
    "\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Try to robustly extract the assistant's response\n",
    "assistant_response = text.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
    "# Or if using older templates maybe: text.split(\"assistant\")[-1].strip()\n",
    "\n",
    "print(\"\\nGenerated Query:\")\n",
    "print(assistant_response) # Print only the assistant part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Save Model ---\n",
    "print(\"\\n--- Saving Model ---\")\n",
    "trainer.model.save_pretrained(new_model) # Saves only the adapters\n",
    "# For merging later (requires more memory/CPU):\n",
    "# del model # Free VRAM\n",
    "# torch.cuda.empty_cache()\n",
    "# base_model_reload = AutoModelForCausalLM.from_pretrained(base_model, torch_dtype=torch_dtype, device_map='cpu') # Load on CPU\n",
    "# model = PeftModel.from_pretrained(base_model_reload, new_model)\n",
    "# model = model.merge_and_unload()\n",
    "# model.save_pretrained(f\"{new_model}-merged\")\n",
    "# tokenizer.save_pretrained(f\"{new_model}-merged\")\n",
    "\n",
    "# Push adapters to hub\n",
    "try:\n",
    "    trainer.model.push_to_hub(new_model, use_temp_dir=False)\n",
    "    tokenizer.push_to_hub(new_model, use_temp_dir=False) # Push tokenizer too\n",
    "    print(\"Model and tokenizer pushed to hub.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error pushing to hub: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # --- Evaluation Script (Run Separately or After Freeing Memory) ---\n",
    "# # It's safer to run evaluation in a separate step/script if memory is tight\n",
    "# # If you run it here, ensure you have enough VRAM *after* training.\n",
    "\n",
    "# print(\"\\n--- Running Evaluation Script ---\")\n",
    "# from torch.utils.data import DataLoader\n",
    "# import json\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Reload the dataset if necessary (might have been modified by trainer)\n",
    "# dataset = load_dataset(\"json\", data_files=data_files)[\"train\"]\n",
    "\n",
    "# # Ensure tokenizer has pad token for batching\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# def collate_fn_eval(batch):\n",
    "#     prompts = []\n",
    "#     for example in batch:\n",
    "#         messages = [{\"role\": \"system\", \"content\": instruction},\n",
    "#                     {\"role\": \"user\", \"content\": example[\"question\"]}]\n",
    "#         prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "#         prompts.append(prompt)\n",
    "\n",
    "#     # Tokenize the batch of prompts\n",
    "#     tokenized = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_SEQ_LENGTH).to(model.device) # Use model.device\n",
    "\n",
    "#     questions = [example[\"question\"] for example in batch]\n",
    "#     queries = [example[\"query\"] for example in batch]\n",
    "#     return tokenized, questions, queries\n",
    "\n",
    "# # Use a smaller batch size for evaluation if necessary\n",
    "# eval_batch_size = 2 # ADJUST AS NEEDED\n",
    "# dataloader = DataLoader(dataset, batch_size=eval_batch_size, collate_fn=collate_fn_eval)\n",
    "\n",
    "# results = []\n",
    "# model.eval() # Set model to evaluation mode\n",
    "\n",
    "# print(\"Generating predictions for evaluation...\")\n",
    "# for inputs, questions, queries in tqdm(dataloader):\n",
    "#     with torch.no_grad(): # Ensure no gradients are computed\n",
    "#         # Generate predictions\n",
    "#         outputs = model.generate(\n",
    "#             **inputs,\n",
    "#             max_new_tokens=512, # Max length for the generated SQL\n",
    "#             num_return_sequences=1,\n",
    "#             pad_token_id=tokenizer.eos_token_id\n",
    "#             )\n",
    "\n",
    "#     # Decode outputs - skip special tokens AND the prompt part\n",
    "#     # We need to decode individually and remove the prompt contamination\n",
    "#     decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "#     # Extract only the generated part after the prompt\n",
    "#     model_queries = []\n",
    "#     input_lengths = inputs['input_ids'].shape[1] # Length of the tokenized prompt\n",
    "#     for i in range(len(decoded_outputs)):\n",
    "#          # Decode only the generated tokens\n",
    "#          generated_tokens = outputs[i][input_lengths:]\n",
    "#          mq = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "#          # Alternative (less reliable) split method:\n",
    "#          # mq = decoded_outputs[i].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
    "#          model_queries.append(mq)\n",
    "\n",
    "\n",
    "#     for q, gt, mq in zip(questions, queries, model_queries):\n",
    "#         results.append({\n",
    "#             \"question\": q,\n",
    "#             \"query\": gt,\n",
    "#             \"model_query\": mq\n",
    "#         })\n",
    "\n",
    "# print(f\"Generated {len(results)} predictions.\")\n",
    "# # Save results to a file\n",
    "# output_filename = \"complex_queries_train_model_predictions.json\"\n",
    "# print(f\"Saving predictions to {output_filename}...\")\n",
    "# with open(output_filename, \"w\") as f:\n",
    "#     json.dump(results, f, indent=4)\n",
    "# print(\"Predictions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7070614,
     "sourceId": 11305975,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7073345,
     "sourceId": 11309709,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
